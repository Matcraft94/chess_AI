{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import chess\n",
    "import chess.pgn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_games(pgn_file):\n",
    "    count = 0\n",
    "    \n",
    "    with open(pgn_file) as pgn:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break  # Fin del archivo\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fen_positions(pgn_file):\n",
    "    fen_positions = []\n",
    "    total_games = count_games(pgn_file)\n",
    "    \n",
    "    with open(pgn_file) as pgn:\n",
    "        for _ in tqdm(range(total_games), desc=\"Processing games\"):\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break  # Fin del archivo\n",
    "            \n",
    "            board = game.board()\n",
    "            for move in game.mainline_moves():\n",
    "                board.push(move)\n",
    "                fen_positions.append(board.fen())\n",
    "    \n",
    "    return fen_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para convertir el el tablero de ajedrez a tensor y visceversa\n",
    "def board_to_tensor(board):\n",
    "    pieces = ['P', 'N', 'B', 'R', 'Q', 'K', 'p', 'n', 'b', 'r', 'q', 'k']\n",
    "    tensor = torch.zeros(12, 8, 8)\n",
    "    for i, piece in enumerate(pieces):\n",
    "        for pos in board.pieces(chess.Piece.from_symbol(piece).piece_type, chess.WHITE if piece.isupper() else chess.BLACK):\n",
    "            tensor[i, pos // 8, pos % 8] = 1\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_move(tensor):\n",
    "    move_index = tensor.argmax().item()\n",
    "    from_square = move_index // 64\n",
    "    to_square = move_index % 64\n",
    "    return chess.Move(from_square, to_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.fen_files = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fen_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fen_path = os.path.join(self.root_dir, self.fen_files[idx])\n",
    "        board = chess.Board(fen_path[:-4])  # Asumiendo que el nombre del archivo es el FEN\n",
    "        image = Image.open(fen_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return board, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessPGNDataset(Dataset):\n",
    "    def __init__(self, fen_positions, transform=None):\n",
    "        self.fen_positions = fen_positions\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fen_positions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fen = self.fen_positions[idx]\n",
    "        board = chess.Board(fen)\n",
    "        \n",
    "        # Aquí puedes aplicar la transformación si es necesario, por ejemplo, si estás utilizando imágenes en lugar de FEN\n",
    "        # Para simplificar, asumiremos que estás utilizando notaciones FEN directamente en el modelo\n",
    "        if self.transform:\n",
    "            board = self.transform(board)\n",
    "        # Convierte el objeto `chess.Board` en un tensor\n",
    "        board_tensor = board_to_tensor(board)\n",
    "\n",
    "        return board_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, fen_list, uci_move_list, transform=None):\n",
    "        self.fen_list = fen_list\n",
    "        self.uci_move_list = uci_move_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fen_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fen = self.fen_list[idx]\n",
    "        board = chess.Board(fen)\n",
    "        move = self.uci_move_list[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            # Aplicar transformaciones en el tablero si es necesario\n",
    "            # Aquí, asumimos que la transformación se realiza en el tablero, no en la imagen\n",
    "            board = self.transform(board)\n",
    "\n",
    "        return board, move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_onehot(move, size):\n",
    "    \"\"\"Convierte un movimiento a un vector one-hot de tamaño size.\"\"\"\n",
    "    onehot = np.zeros(size)\n",
    "    onehot[move] = 1\n",
    "    return onehot\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, fen_list, uci_move_list, size, transform=None):\n",
    "        self.fen_list = fen_list\n",
    "        self.uci_move_list = uci_move_list\n",
    "        self.size = size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fen_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fen = self.fen_list[idx]\n",
    "        board = chess.Board(fen)\n",
    "        move = self.uci_move_list[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            board = self.transform(board)\n",
    "\n",
    "        board_tensor = board_to_tensor(board)\n",
    "        move_tensor = torch.tensor(move_to_onehot(move, self.size))\n",
    "        \n",
    "        return board_tensor, move_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, fen_list, move_list, transform=None):\n",
    "        self.fen_list = fen_list\n",
    "        self.move_list = move_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fen_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fen = self.fen_list[idx]\n",
    "        board = chess.Board().set_board_fen(fen)\n",
    "        move = self.uci_move_list[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            board = self.transform(board)\n",
    "\n",
    "        board_tensor = board_to_tensor(board)\n",
    "        move_tensor = torch.tensor(move_to_onehot(move, size=NUM_POSSIBLE_MOVES))\n",
    "\n",
    "        return board_tensor, move_tensor\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, board):\n",
    "        return board.pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessAI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessAI, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 4096)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(4096, 4672)  # Modificar la cantidad de salidas\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.relu2(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)  # Agregar capa Softmax\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgn_file = \"C:/Users/mated/Documents/GitHub/CHESS_DATA/lichess_db_standard_rated_2017-03.pgn\"\n",
    "pgn_file = \"C:/Users/mated/Documents/GitHub/CHESS_DATA/lichess_db_standard_rated_2013-01.pgn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChessDataset(\"C:/Users/mated/Documents/GitHub/CHESS_DATA/lichess_db_standard_rated_2013-01.pgn\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, pgn_file):\n",
    "        self.games = []\n",
    "        with open(pgn_file) as f:\n",
    "            game = []\n",
    "            for line in f:\n",
    "                if line.startswith('[Event'):\n",
    "                    if game:\n",
    "                        self.games.append(game)\n",
    "                    game = []\n",
    "                if line.startswith('1.'):\n",
    "                    moves = line.strip().split()[1:]\n",
    "                    game.append(moves)\n",
    "            if game:\n",
    "                self.games.append(game)\n",
    "\n",
    "        self.data = []\n",
    "        for game in self.games:\n",
    "            board = chess.Board()\n",
    "            fen_moves = []\n",
    "            for moves in game:\n",
    "                for move in moves:\n",
    "                    fen_moves.append((board.fen(), move))\n",
    "                    board.push_uci(move)\n",
    "            self.data.append(fen_moves)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fen_positions = extract_fen_positions(pgn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Divide las posiciones FEN en datos de entrenamiento y prueba\n",
    "# train_fen_positions, test_fen_positions = train_test_split(fen_positions, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crea los conjuntos de datos\n",
    "# train_dataset = ChessPGNDataset(train_fen_positions)\n",
    "# test_dataset = ChessPGNDataset(test_fen_positions)\n",
    "\n",
    "# # Crea los DataLoader\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fen_and_moves_from_pgn(pgn_file):\n",
    "    fen_list = []\n",
    "    uci_move_list = []\n",
    "    total_games = count_games(pgn_file)\n",
    "    \n",
    "    with open(pgn_file) as pgn:\n",
    "        for _ in tqdm(range(total_games), desc=\"Processing games\"):\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break  # Fin del archivo\n",
    "            \n",
    "            board = game.board()\n",
    "            for move in game.mainline_moves():\n",
    "                board.push(move)\n",
    "                fen_list.append(board.fen())\n",
    "                uci_move_list.append(move.uci())\n",
    "    \n",
    "    return fen_list, uci_move_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 121332/121332 [13:30<00:00, 149.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cargar las posiciones FEN y los movimientos UCI a partir del archivo PGN\n",
    "fen_list, uci_move_list = extract_fen_and_moves_from_pgn(pgn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir las listas de FEN y movimientos UCI en conjuntos de entrenamiento y prueba\n",
    "# train_fen_positions, test_fen_positions = train_test_split(fen_list, test_size=0.2, random_state=42)\n",
    "# train_uci_move_list, test_uci_move_list = train_test_split(uci_move_list, test_size=0.2, random_state=42)\n",
    "train_fen_list, test_fen_list, train_uci_move_list, test_uci_move_list = train_test_split(fen_list, uci_move_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear conjuntos de datos y DataLoaders para entrenamiento y prueba\n",
    "train_dataset = ChessDataset(train_fen_list, train_uci_move_list, transform=transform)\n",
    "test_dataset = ChessDataset(test_fen_list, test_uci_move_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected position part of fen, got multiple parts: '2q2rk1/1n2bpp1/2pp3p/1p2p2n/1P2P3/2PP1N1P/1BBQ1PPK/R7 b - - 1 21'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, (fen, uci_move)  \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_dataloader):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLos tamaños de los elementos son: fen=\u001b[39m\u001b[39m{\u001b[39;00mfen\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, uni_move=\u001b[39m\u001b[39m{\u001b[39;00muci_move\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mChessDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     11\u001b[0m     fen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfen_list[idx]\n\u001b[1;32m---> 12\u001b[0m     board \u001b[39m=\u001b[39m chess\u001b[39m.\u001b[39;49mBoard()\u001b[39m.\u001b[39;49mset_board_fen(fen)\n\u001b[0;32m     13\u001b[0m     move \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muci_move_list[idx]\n\u001b[0;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\chess\\__init__.py:2568\u001b[0m, in \u001b[0;36mBoard.set_board_fen\u001b[1;34m(self, fen)\u001b[0m\n\u001b[0;32m   2567\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_board_fen\u001b[39m(\u001b[39mself\u001b[39m, fen: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2568\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_board_fen(fen)\n\u001b[0;32m   2569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclear_stack()\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\chess\\__init__.py:1049\u001b[0m, in \u001b[0;36mBaseBoard.set_board_fen\u001b[1;34m(self, fen)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_board_fen\u001b[39m(\u001b[39mself\u001b[39m, fen: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m    Parses *fen* and sets up the board, where *fen* is the board part of\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39m    a FEN.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m    :raises: :exc:`ValueError` if syntactically invalid.\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_board_fen(fen)\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\chess\\lib\\site-packages\\chess\\__init__.py:990\u001b[0m, in \u001b[0;36mBaseBoard._set_board_fen\u001b[1;34m(self, fen)\u001b[0m\n\u001b[0;32m    988\u001b[0m fen \u001b[39m=\u001b[39m fen\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    989\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m fen:\n\u001b[1;32m--> 990\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected position part of fen, got multiple parts: \u001b[39m\u001b[39m{\u001b[39;00mfen\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    992\u001b[0m \u001b[39m# Ensure the FEN is valid.\u001b[39;00m\n\u001b[0;32m    993\u001b[0m rows \u001b[39m=\u001b[39m fen\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: expected position part of fen, got multiple parts: '2q2rk1/1n2bpp1/2pp3p/1p2p2n/1P2P3/2PP1N1P/1BBQ1PPK/R7 b - - 1 21'"
     ]
    }
   ],
   "source": [
    "for i, (fen, uci_move)  in enumerate(test_dataloader):\n",
    "    print(f'Los tamaños de los elementos son: fen={fen.shape}, uni_move={uci_move.shape}')\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creamos conjuntos de datos: dataloaders\n",
    "# transform = transforms.Compose([transforms.Resize((8, 8)), transforms.ToTensor()])\n",
    "\n",
    "# train_dataset = ChessDataset(\"train\", transform=transform)\n",
    "# test_dataset = ChessDataset(\"test\", transform=transform)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChessAI()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# metrics = [nn.MSELoss(), torchmetrics.Accuracy(), torchmetrics.F1(num_clases=2)]#(num_classes=4672)]\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# metrics = [\n",
    "#     mean_squared_error,\n",
    "#     mean_absolute_error,\n",
    "#     nn.CrossEntropyLoss()\n",
    "#     # torchmetrics.Accuracy(num_classes=4672),\n",
    "#     # torchmetrics.F1(num_classes=4672, average='macro'),\n",
    "# ]\n",
    "\n",
    "metrics = {\n",
    "    'mse': nn.MSELoss(),\n",
    "    'mse': nn.MSELoss(),\n",
    "    'mae': nn.L1Loss()\n",
    "    # 'accuracy': torchmetrics.Accuracy(num_classes=4672),\n",
    "    # 'f1_score': torchmetrics.F1(num_classes=4672, average='macro')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(12, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "\n",
    "# train_metrics = {key: [] for key in metrics.keys()}\n",
    "# test_metrics = {key: [] for key in metrics.keys()}\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     train_metric_vals = {key: 0 for key in metrics.keys()}\n",
    "#     for i, (board, image) in enumerate(train_dataloader):\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         input_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "#         output_tensor = model(input_tensor)\n",
    "#         target_tensor = image.view(1, -1).to(device)\n",
    "\n",
    "#         loss = criterion(output_tensor, target_tensor)\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         for metric_name, metric_fn in metrics.items():\n",
    "#             metric_val = metric_fn(output_tensor, target_tensor)\n",
    "#             train_metric_vals[metric_name] += metric_val.item()\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     train_loss /= len(train_dataloader)\n",
    "#     train_losses.append(train_loss)\n",
    "#     for metric_name in metrics.keys():\n",
    "#         train_metric_vals[metric_name] /= len(train_dataloader)\n",
    "#         train_metrics[metric_name].append(train_metric_vals[metric_name])\n",
    "\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     test_metric_vals = {key: 0 for key in metrics.keys()}\n",
    "#     for i, (board, image) in enumerate(test_dataloader):\n",
    "#         input_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "#         output_tensor = model(input_tensor)\n",
    "#         target_tensor = image.view(1, -1).to(device)\n",
    "\n",
    "#         loss = criterion(output_tensor, target_tensor)\n",
    "#         test_loss += loss.item()\n",
    "\n",
    "#         for metric_name, metric_fn in metrics.items():\n",
    "#             metric_val = metric_fn(output_tensor, target_tensor)\n",
    "#             test_metric_vals[metric_name] += metric_val.item()\n",
    "\n",
    "#     test_loss /= len(test_dataloader)\n",
    "#     test_losses.append(test_loss)\n",
    "#     for metric_name in metrics.keys():\n",
    "#         test_metric_vals[metric_name] /= len(test_dataloader)\n",
    "#         test_metrics[metric_name].append(test_metric_vals[metric_name])\n",
    "\n",
    "#     print(f\"Epoch: {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "#     for metric_name in metrics.keys():\n",
    "#         print(f\"    {metric_name.capitalize()}: Train {train_metric_vals[metric_name]:.4f}, Test {test_metric_vals[metric_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_metrics = {key: [] for key in metrics.keys()}\n",
    "test_metrics = {key: [] for key in metrics.keys()}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_metric_vals = {key: 0 for key in metrics.keys()}\n",
    "    for i, (board, move) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_tensor = board_to_tensor(board).to(device)\n",
    "        output_tensor = model(input_tensor)\n",
    "        target_tensor = torch.tensor(move).to(device)\n",
    "\n",
    "        loss = criterion(output_tensor, target_tensor)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        for metric_name, metric_fn in metrics.items():\n",
    "            if metric_name == 'mse':\n",
    "                metric_val = metric_fn(output_tensor, target_tensor.float())\n",
    "            else:\n",
    "                metric_val = metric_fn(output_tensor.argmax(dim=1), target_tensor)\n",
    "            train_metric_vals[metric_name] += metric_val.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "    for metric_name in metrics.keys():\n",
    "        train_metric_vals[metric_name] /= len(train_dataloader)\n",
    "        train_metrics[metric_name].append(train_metric_vals[metric_name])\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_metric_vals = {key: 0 for key in metrics.keys()}\n",
    "    for i, (board, move) in enumerate(test_dataloader):\n",
    "        input_tensor = board_to_tensor(board).to(device)\n",
    "        output_tensor = model(input_tensor)\n",
    "        target_tensor = torch.tensor(move).to(device)\n",
    "\n",
    "        loss = criterion(output_tensor, target_tensor)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        for metric_name, metric_fn in metrics.items():\n",
    "            if metric_name == 'mse':\n",
    "                metric_val = metric_fn(output_tensor, target_tensor.float())\n",
    "            else:\n",
    "                metric_val = metric_fn(output_tensor.argmax(dim=1), target_tensor)\n",
    "            test_metric_vals[metric_name] += metric_val.item()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_losses.append(test_loss)\n",
    "    for metric_name in metrics.keys():\n",
    "        test_metric_vals[metric_name] /= len(test_dataloader)\n",
    "        test_metrics[metric_name].append(test_metric_vals[metric_name])\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    for metric_name in metrics.keys():\n",
    "        print(f\"    {metric_name.capitalize()}: Train {train_metric_vals[metric_name]:.4f}, Test {test_metric_vals[metric_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"chess_ai_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar función de pérdida\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar métricas\n",
    "for metric_name, metric_values in metric_dict.items():\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(metric_values, label=metric_name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'{metric_name} over Time')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de pérdida\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_losses_ce, label='Train CE')\n",
    "plt.plot(test_losses_ce, label='Test CE')\n",
    "plt.plot(train_losses_mse, label='Train MSE')\n",
    "plt.plot(test_losses_mse, label='Test MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Function Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Métricas\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_accuracies_ce, label='Train Accuracy CE')\n",
    "plt.plot(test_accuracies_ce, label='Test Accuracy CE')\n",
    "plt.plot(train_accuracies_mse, label='Train Accuracy MSE')\n",
    "plt.plot(test_accuracies_mse, label='Test Accuracy MSE')\n",
    "plt.plot(train_f1_scores_ce, label='Train F1-Score CE')\n",
    "plt.plot(test_f1_scores_ce, label='Test F1-Score CE')\n",
    "plt.plot(train_f1_scores_mse, label='Train F1-Score MSE')\n",
    "plt.plot(test_f1_scores_mse, label='Test F1-Score MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Metric Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics_dict = {'train_loss': train_losses,\n",
    "                'train_mse': train_mses,\n",
    "                'train_acc': train_accs,\n",
    "                'train_f1': train_f1s,\n",
    "                'test_loss': test_losses,\n",
    "                'test_mse': test_mses,\n",
    "                'test_acc': test_accs,\n",
    "                'test_f1': test_f1s}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "metrics_df[['train_loss', 'test_loss']].plot(ax=axs[0, 0], title='Loss')\n",
    "metrics_df[['train_mse', 'test_mse']].plot(ax=axs[0, 1], title='MSE')\n",
    "metrics_df[['train_acc', 'test_acc']].plot(ax=axs[1, 0], title='Accuracy')\n",
    "metrics_df[['train_f1', 'test_f1']].plot(ax=axs[1, 1], title='F1 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación de pérdidas y métricas por época\n",
    "\n",
    "# Definir los datos\n",
    "epochs = list(range(1, num_epochs+1))\n",
    "train_loss_values = [train_metrics_dict['loss'][i] for i in range(num_epochs)]\n",
    "test_loss_values = [test_metrics_dict['loss'][i] for i in range(num_epochs)]\n",
    "mse_values = [test_metrics_dict['mse'][i] for i in range(num_epochs)]\n",
    "accuracy_values = [test_metrics_dict['accuracy'][i] for i in range(num_epochs)]\n",
    "f1score_values = [test_metrics_dict['f1score'][i] for i in range(num_epochs)]\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# Plotear las pérdidas\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Épocas')\n",
    "ax1.set_ylabel('Pérdida', color=color)\n",
    "ax1.plot(epochs, train_loss_values, color=color, linestyle='--', label='Train Loss')\n",
    "ax1.plot(epochs, test_loss_values, color=color, label='Test Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Crear los ejes secundarios\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plotear las métricas\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Métricas', color=color)\n",
    "ax2.plot(epochs, mse_values, color=color, linestyle=':', label='MSE')\n",
    "ax2.plot(epochs, accuracy_values, color=color, linestyle='-.', label='Accuracy')\n",
    "ax2.plot(epochs, f1score_values, color=color, linestyle='--', label='F1-Score')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Añadir leyendas y título\n",
    "plt.legend()\n",
    "plt.title('Comparación de pérdidas y métricas por época')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación de pérdidas de entrenamiento y prueba\n",
    "\n",
    "# Definir los datos\n",
    "epochs = list(range(1, num_epochs+1))\n",
    "train_loss_values = [train_metrics_dict['loss'][i] for i in range(num_epochs)]\n",
    "test_loss_values = [test_metrics_dict['loss'][i] for i in range(num_epochs)]\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# Plotear las pérdidas\n",
    "ax.plot(epochs, train_loss_values, label='Train Loss')\n",
    "ax.plot(epochs, test_loss_values, label='Test Loss')\n",
    "\n",
    "# Añadir leyendas y título\n",
    "plt.legend()\n",
    "plt.title('Comparación de pérdidas de entrenamiento y prueba por época')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de métricas de prueba por época\n",
    "\n",
    "# Definir los datos\n",
    "epochs = list(range(1, num_epochs+1))\n",
    "mse_values = [test_metrics_dict['mse'][i] for i in range(num_epochs)]\n",
    "accuracy_values = [test_metrics_dict['accuracy'][i] for i in range(num_epochs)]\n",
    "f1score_values = [test_metrics_dict['f1score'][i] for i in range(num_epochs)]\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# Plotear las métricas\n",
    "for i, (board, image) in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    input_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "    output_tensor = model(input_tensor)\n",
    "    target_tensor = image.view(1, -1).to(device)\n",
    "\n",
    "    loss = criterion(output_tensor, target_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    train_loss += loss.item()\n",
    "        \n",
    "    # Calculate accuracy\n",
    "    _, predicted = torch.max(output_tensor.data, 1)\n",
    "    total += target_tensor.size(1)\n",
    "    correct += (predicted == target_tensor).sum().item()\n",
    "\n",
    "train_accuracy = correct / total\n",
    "train_accuracies.append(train_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, podemos calcular la precisión en el conjunto de prueba al final de cada época:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (board, image) in enumerate(test_dataloader):\n",
    "        input_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "        output_tensor = model(input_tensor)\n",
    "        target_tensor = image.view(1, -1).to(device)\n",
    "\n",
    "        loss = criterion(output_tensor, target_tensor)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output_tensor.data, 1)\n",
    "        total += target_tensor.size(1)\n",
    "        correct += (predicted == target_tensor).sum().item()\n",
    "\n",
    "test_accuracy = correct / total\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy by Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\")\n",
    "input_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "output_tensor = model(input_tensor)\n",
    "image = tensor_to_image(output_tensor.squeeze().cpu())\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(board)\n",
    "ax[1].imshow(image)\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
