{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHess RL Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se está utilizando el dispositivo cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Se está utilizando el dispositivo',device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el ambiente del juego y las respectivas reglas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_tensor(board):\n",
    "    piece_map = board.piece_map()\n",
    "    board_tensor = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "\n",
    "    for pos, piece in piece_map.items():\n",
    "        rank, file = chess.square_rank(pos), chess.square_file(pos)\n",
    "        piece_idx = piece.piece_type - 1 + (6 if piece.color == chess.BLACK else 0)\n",
    "        board_tensor[piece_idx, rank, file] = 1\n",
    "\n",
    "    return board_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessEnvironment:\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board.reset()\n",
    "        return self.board_to_array(self.board)\n",
    "    \n",
    "    def board_to_array(self, board):\n",
    "        # Convierte el tablero en una matriz 8x8x12 que representa las piezas y sus posiciones.\n",
    "        piece_symbols = \"PRNBQKprnbqk\"\n",
    "        piece_indices = {symbol: i for i, symbol in enumerate(piece_symbols)}\n",
    "        board_matrix = np.zeros((12, 8, 8))\n",
    "\n",
    "        for i in range(64):\n",
    "            piece = board.piece_at(i)\n",
    "            if piece:\n",
    "                piece_index = piece_indices[piece.symbol()]\n",
    "                row, col = divmod(i, 8)\n",
    "                board_matrix[piece_index, row, col] = 1\n",
    "\n",
    "        return board_matrix\n",
    "\n",
    "    def step(self, move):\n",
    "        # Aplicar el movimiento al tablero y devolver el nuevo estado, recompensa y si el juego ha terminado.\n",
    "        game_over = False\n",
    "        reward = 0\n",
    "\n",
    "        if move in self.legal_moves():\n",
    "            self.board.push(move)\n",
    "            game_over = self.board.is_game_over()\n",
    "            if game_over:\n",
    "                reward = self.get_reward()\n",
    "        else:\n",
    "            raise ValueError(\"Illegal move\")\n",
    "\n",
    "        next_state = self.board_to_array(self.board)\n",
    "        return next_state, reward, game_over\n",
    "\n",
    "    def legal_moves(self):\n",
    "        return list(self.board.legal_moves)\n",
    "\n",
    "    # def is_game_over(self):\n",
    "    #     return self.board.is_game_over()\n",
    "    def is_game_over(self):  # Modifica la función para que no requiera argumentos adicionales\n",
    "        return self.board.is_game_over()\n",
    "\n",
    "    def get_reward(self):\n",
    "        result = self.board.result()\n",
    "        if result == \"1-0\":  # White wins\n",
    "            return 1\n",
    "        elif result == \"0-1\":  # Black wins\n",
    "            return -1\n",
    "        else:  # Draw\n",
    "            return 0\n",
    "    \n",
    "    def get_state(self):\n",
    "        return board_to_tensor(self.board)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class ChessNetwork(nn.Module):\n",
    "    def __init__(self, num_residual_blocks=3, num_channels=256):\n",
    "        super(ChessNetwork, self).__init__()\n",
    "\n",
    "        self.conv_input = nn.Conv2d(12, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_input = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_residual_blocks)])\n",
    "\n",
    "        self.conv_policy = nn.Conv2d(num_channels, 2, kernel_size=1)\n",
    "        self.bn_policy = nn.BatchNorm2d(2)\n",
    "        self.fc_policy = nn.Linear(2 * 8 * 8, 4096)  # 4096 es el número máximo de movimientos legales en ajedrez\n",
    "\n",
    "        self.conv_value = nn.Conv2d(num_channels, 1, kernel_size=1)\n",
    "        self.bn_value = nn.BatchNorm2d(1)\n",
    "        self.fc_value1 = nn.Linear(8 * 8, 256)\n",
    "        self.fc_value2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
    "        x = self.residual_blocks(x)\n",
    "\n",
    "        policy = F.relu(self.bn_policy(self.conv_policy(x)))\n",
    "        policy = policy.view(-1, 2 * 8 * 8)\n",
    "        policy = F.softmax(self.fc_policy(policy), dim=-1)\n",
    "\n",
    "        value = F.relu(self.bn_value(self.conv_value(x)))\n",
    "        value = value.view(-1, 8 * 8)\n",
    "        value = F.relu(self.fc_value1(value))\n",
    "        value = torch.tanh(self.fc_value2(value))\n",
    "\n",
    "        return policy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNetworkreduced(nn.Module):\n",
    "    def __init__(self, num_residual_blocks=1, num_channels=64):\n",
    "        super(ChessNetworkreduced, self).__init__()\n",
    "\n",
    "        self.conv_input = nn.Conv2d(12, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_input = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_residual_blocks)])\n",
    "\n",
    "        self.conv_policy = nn.Conv2d(num_channels, 2, kernel_size=1)\n",
    "        self.bn_policy = nn.BatchNorm2d(2)\n",
    "        self.fc_policy = nn.Linear(2 * 8 * 8, 4096)  # 4096 es el número máximo de movimientos legales en ajedrez\n",
    "\n",
    "        self.conv_value = nn.Conv2d(num_channels, 1, kernel_size=1)\n",
    "        self.bn_value = nn.BatchNorm2d(1)\n",
    "        self.fc_value1 = nn.Linear(8 * 8, 256)\n",
    "        self.fc_value2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
    "        x = self.residual_blocks(x)\n",
    "\n",
    "        policy = F.relu(self.bn_policy(self.conv_policy(x)))\n",
    "        policy = policy.view(-1, 2 * 8 * 8)\n",
    "        policy = F.softmax(self.fc_policy(policy), dim=-1)\n",
    "\n",
    "        value = F.relu(self.bn_value(self.conv_value(x)))\n",
    "        value = value.view(-1, 8 * 8)\n",
    "        value = F.relu(self.fc_value1(value))\n",
    "        value = torch.tanh(self.fc_value2(value))\n",
    "\n",
    "        return policy, value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    def __init__(self, parent, prior, action):\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.prior = prior\n",
    "\n",
    "    def expand(self, env, action_probs):\n",
    "        for move, prob in action_probs.items():\n",
    "            if move not in self.children:\n",
    "                self.children[move] = MCTSNode(self, prob, move)\n",
    "\n",
    "    def is_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select_child(self):\n",
    "        C = 1.0  # Parámetro de exploración\n",
    "        best_score = None\n",
    "        best_action = None\n",
    "        best_child = None\n",
    "\n",
    "        for action, child in self.children.items():\n",
    "            score = child.get_ucb_score(C)\n",
    "            if best_score is None or score > best_score:\n",
    "                best_score = score\n",
    "                best_action = action\n",
    "                best_child = child\n",
    "\n",
    "        return best_action, best_child\n",
    "\n",
    "    def get_ucb_score(self, C):\n",
    "        Q = self.value()  # Valor medio\n",
    "        U = C * self.prior * math.sqrt(self.parent.visit_count) / (1 + self.visit_count)  # Potencial de mejora\n",
    "        return Q + U\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "        self.visit_count += 1\n",
    "        self.value_sum += value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def index_to_move(index):\n",
    "    from_square = index // 64\n",
    "    to_square = index % 64\n",
    "    return chess.Move(from_square, to_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcts(model, env, num_simulations, temperature):\n",
    "    root = MCTSNode(None, 1.0, None)\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        board_copy = env.board.copy()\n",
    "\n",
    "        # Selección y expansión\n",
    "        while node.is_expanded():\n",
    "            action, node = node.select_child()\n",
    "            board_copy.push(action)\n",
    "\n",
    "        # Simulación\n",
    "        if not env.is_game_over():\n",
    "            legal_moves = list(board_copy.legal_moves)\n",
    "            state = env.board_to_array(board_copy)\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            policy, value = model(state_tensor)\n",
    "            policy = policy.cpu().detach().numpy().flatten()\n",
    "\n",
    "            if len(legal_moves) > 0:  # Verifica si hay al menos un movimiento legal\n",
    "                action_probs = {move: policy[move_to_index(move)] for move in legal_moves}\n",
    "                node.expand(env, action_probs)\n",
    "            else:\n",
    "                action_probs = {}  # Inicializa un diccionario vacío si no hay movimientos legales\n",
    "\n",
    "            value = value.item()\n",
    "        else:\n",
    "            value = env.get_reward(board_copy)\n",
    "\n",
    "        # Retroceso\n",
    "        node.backpropagate(value)\n",
    "\n",
    "    # Calcula la política final a partir del número de visitas de las acciones.\n",
    "    legal_moves = list(env.board.legal_moves)  # Añade esta línea para obtener una lista de movimientos legales\n",
    "    visit_counts = np.array([root.children.get(action, 0).visit_count for action in legal_moves])  # Itera sobre los movimientos legales en lugar de usar num_legal_moves\n",
    "\n",
    "    if temperature == 0:\n",
    "        action_idx = np.argmax(visit_counts)\n",
    "        policy = np.zeros_like(visit_counts)\n",
    "        policy[action_idx] = 1\n",
    "    else:\n",
    "        visit_counts = visit_counts ** (1 / temperature)\n",
    "        policy = visit_counts / visit_counts.sum()\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.pgn\n",
    "\n",
    "def load_games_from_pgn(pgn_file, max_games=None):\n",
    "    games = []\n",
    "    with open(pgn_file, \"r\") as pgn:\n",
    "        for _ in tqdm(range(max_games) if max_games else tqdm(pgn)):\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "            if max_games and len(games) >= max_games:\n",
    "                break\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(model, env, game, num_mcts_simulations, temperature, return_result=False):\n",
    "    states = []\n",
    "    policy_targets = []\n",
    "    value_targets = []\n",
    "\n",
    "    for move in game.mainline_moves():\n",
    "        if not env.board.is_game_over():\n",
    "            policy = run_mcts(model, env, num_mcts_simulations, temperature)\n",
    "\n",
    "            legal_moves = list(env.legal_moves())  \n",
    "            if len(legal_moves) > 0:  \n",
    "                env.board.push(move)\n",
    "                states.append(env.get_state().copy())\n",
    "\n",
    "                padded_policy = np.zeros(4096)\n",
    "                padded_policy[:len(policy)] = policy\n",
    "                policy_targets.append(padded_policy)\n",
    "\n",
    "    result = env.board.result()\n",
    "\n",
    "    if result == \"1-0\":\n",
    "        value_targets = [1] * len(states)\n",
    "    elif result == \"0-1\":\n",
    "        value_targets = [-1] * len(states)\n",
    "    else:\n",
    "        value_targets = [0] * len(states)\n",
    "\n",
    "    if return_result:\n",
    "        return result\n",
    "    else:\n",
    "        return states, policy_targets, value_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_games(model, games, num_mcts_simulations=8, temperature=1.0):\n",
    "    states, policy_targets, value_targets = [], [], []\n",
    "\n",
    "    for game in games:\n",
    "        env = ChessEnvironment()\n",
    "        game_states, game_policies, game_values = play_game(model, env, game, num_mcts_simulations, temperature)\n",
    "        states.extend(game_states)\n",
    "        policy_targets.extend(game_policies)\n",
    "        value_targets.extend(game_values)\n",
    "\n",
    "    return states, policy_targets, value_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, states, policy_targets, value_targets, device):\n",
    "    states = torch.tensor(np.array(states), dtype=torch.float32).to(device)\n",
    "    policy_targets = torch.tensor(np.array(policy_targets), dtype=torch.float32).to(device)\n",
    "    value_targets = torch.tensor(np.array(value_targets), dtype=torch.float32).to(device)\n",
    "\n",
    "    policies, values = model(states)\n",
    "\n",
    "    # Utilizar nll_loss en lugar de binary_cross_entropy\n",
    "    policy_loss = F.nll_loss(torch.log(policies), torch.argmax(policy_targets, dim=1))\n",
    "    value_loss = F.mse_loss(values.view(-1), value_targets)\n",
    "\n",
    "    total_loss = policy_loss + value_loss\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_game(model, env, num_mcts_simulations):\n",
    "    while not env.is_game_over():\n",
    "        state = env.board_to_array(env.board)\n",
    "        policy, _ = run_mcts(model, env, num_mcts_simulations, temperature=0)\n",
    "\n",
    "        action = np.argmax(policy)\n",
    "        legal_moves = list(env.legal_moves())\n",
    "        move = legal_moves[action]\n",
    "\n",
    "        env.step(move)\n",
    "\n",
    "    return env.get_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_and_save_model(model, save_dir=\"saved_models\", num_evaluation_games=100, num_mcts_simulations=800):\n",
    "def evaluate_and_save_model(model, save_dir=\"saved_models\", num_evaluation_games=10, num_mcts_simulations=8):\n",
    "    win_count = 0\n",
    "    draw_count = 0\n",
    "    loss_count = 0\n",
    "\n",
    "    for _ in range(num_evaluation_games):\n",
    "        env = ChessEnvironment()\n",
    "        game_result = evaluate_game(model, env, num_mcts_simulations)\n",
    "\n",
    "        if game_result == 1:\n",
    "            win_count += 1\n",
    "        elif game_result == 0:\n",
    "            draw_count += 1\n",
    "        else:\n",
    "            loss_count += 1\n",
    "\n",
    "    win_rate = win_count / num_evaluation_games\n",
    "    draw_rate = draw_count / num_evaluation_games\n",
    "    loss_rate = loss_count / num_evaluation_games\n",
    "\n",
    "    print(f\"Evaluation results: {num_evaluation_games} games played\")\n",
    "    print(f\"Win rate: {win_rate:.2f}, Draw rate: {draw_rate:.2f}, Loss rate: {loss_rate:.2f}\")\n",
    "\n",
    "    # Guardar el modelo si es mejor que el modelo anteriormente guardado.\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"model_win_rate_{win_rate:.2f}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, num_games=10):\n",
    "    model.eval()  # Cambiar el modelo a modo de evaluación.\n",
    "\n",
    "    num_wins = 0\n",
    "    num_draws = 0\n",
    "    num_losses = 0\n",
    "    for _ in range(num_games):\n",
    "        env = ChessEnvironment()\n",
    "        \n",
    "        game = chess.pgn.Game()\n",
    "        # game_result = play_game(model, env, num_mcts_simulations=50, temperature=0)\n",
    "        game_result = play_game(model, env, game, num_mcts_simulations=50, temperature=0, return_result=True)\n",
    "\n",
    "        if game_result == \"1-0\":\n",
    "            num_wins += 1\n",
    "        elif game_result == \"0-1\":\n",
    "            num_losses += 1\n",
    "        elif game_result == \"1/2-1/2\":\n",
    "            num_draws += 1\n",
    "\n",
    "    win_rate = num_wins / num_games\n",
    "    draw_rate = num_draws / num_games\n",
    "    loss_rate = num_losses / num_games\n",
    "\n",
    "    return win_rate, draw_rate, loss_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, evaluation_interval):\n",
    "    losses = []\n",
    "    min_loss = float(\"inf\")\n",
    "    min_epoch = 0  # Época en la que se alcanzó el mínimo de pérdida.\n",
    "    \n",
    "    progress_bar = tqdm(range(epochs))  # Guarda el objeto tqdm en la variable progress_bar\n",
    "\n",
    "    for epoch in progress_bar:\n",
    "        # Generar partidas de autojugabilidad.\n",
    "        states, actions, rewards = play_games(model)\n",
    "        \n",
    "        # Calcular la pérdida y actualizar los pesos de la red neuronal.\n",
    "        loss = compute_loss(model, states, actions, rewards, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Añadir la pérdida a la lista de pérdidas.\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Evaluar y guardar el modelo en intervalos regulares.\n",
    "        if (epoch + 1) % evaluation_interval == 0:\n",
    "            win_rate, draw_rate, loss_rate = evaluate(model)\n",
    "            print(f\"Evaluation results: {evaluation_interval} games played\")\n",
    "            print(f\"Win rate: {win_rate:.2f}, Draw rate: {draw_rate:.2f}, Loss rate: {loss_rate:.2f}\")\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "                torch.save(model.state_dict(), f\"saved_models\\model_win_rate_{win_rate:.2f}.pt\")\n",
    "                min_epoch = epoch\n",
    "\n",
    "        # Actualizar la barra de progreso con la información de la época actual y la pérdida.\n",
    "        progress_bar.set_description(f\"Epoch {epoch}, Loss {loss.item():.4f}\")\n",
    "    \n",
    "    # Graficar la pérdida a lo largo de las épocas.\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    \n",
    "    # Indicar dónde se alcanzó el mínimo de pérdida.\n",
    "    plt.axvline(x=min_epoch, color='r', linestyle='--')\n",
    "    plt.text(min_epoch, min_loss, f\"Min Loss: {min_loss:.4f}\", color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121332it [04:57, 408.01it/s]\n",
      "121332it [04:57, 408.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos la base de datos\n",
    "pgn_file = \"C:/Users/mated/Documents/GitHub/CHESS_DATA/lichess_db_standard_rated_2013-01.pgn\"\n",
    "\n",
    "# games = load_games_from_pgn(pgn_file, max_games=1000)\n",
    "games = load_games_from_pgn(pgn_file) # Extrae el número todal de juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una partida cargada es: 1. e4 e6 2. d4 b6 3. a3 Bb7 4. Nc3 Nh6 5. Bxh6 gxh6 6. Be2 Qg5 7. Bg4 h5 8. Nf3 Qg6 9. Nh4 Qg5 10. Bxh5 Qxh4 11. Qf3 Kd8 12. Qxf7 Nc6 13. Qe8#\n"
     ]
    }
   ],
   "source": [
    "print('Una partida cargada es:',list( games[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = ChessNetworkreduced(num_residual_blocks=3, num_channels=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 8, 8]           6,976\n",
      "       BatchNorm2d-2             [-1, 64, 8, 8]             128\n",
      "            Conv2d-3             [-1, 64, 8, 8]          36,928\n",
      "       BatchNorm2d-4             [-1, 64, 8, 8]             128\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,928\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "     ResidualBlock-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,928\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "           Conv2d-10             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-12             [-1, 64, 8, 8]               0\n",
      "           Conv2d-13             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-14             [-1, 64, 8, 8]             128\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-17             [-1, 64, 8, 8]               0\n",
      "           Conv2d-18              [-1, 2, 8, 8]             130\n",
      "      BatchNorm2d-19              [-1, 2, 8, 8]               4\n",
      "           Linear-20                 [-1, 4096]         528,384\n",
      "           Conv2d-21              [-1, 1, 8, 8]              65\n",
      "      BatchNorm2d-22              [-1, 1, 8, 8]               2\n",
      "           Linear-23                  [-1, 256]          16,640\n",
      "           Linear-24                    [-1, 1]             257\n",
      "================================================================\n",
      "Total params: 774,922\n",
      "Trainable params: 774,922\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.57\n",
      "Params size (MB): 2.96\n",
      "Estimated Total Size (MB): 3.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Asume un tablero de ajedrez de 8x8 y 12 canales, que representan las diferentes piezas\n",
    "input_shape = (12, 8, 8)\n",
    "summary(model, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "epochs = 20\n",
    "evaluation_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit train(model, optimizer, epochs, evaluation_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1920.00 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2121/2121 [00:27<00:00, 78.25it/s, Loss=1.86]\n",
      "Training:   5%|▌         | 1/20 [32:27<10:16:35, 1947.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.074661058898469\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 2182.42 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2131/2131 [01:18<00:00, 27.28it/s, Loss=3.39]\n",
      "Training:  10%|█         | 2/20 [1:10:07<10:39:27, 2131.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.391339707631899\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 2189.77 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2144/2144 [01:21<00:00, 26.29it/s, Loss=4.69]\n",
      "Training:  15%|█▌        | 3/20 [1:47:59<10:22:00, 2195.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 3.394744380085326\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1797.02 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2125/2125 [01:19<00:00, 26.87it/s, Loss=nan]\n",
      "Training:  20%|██        | 4/20 [2:19:15<9:11:49, 2069.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: nan\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1809.66 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2163/2163 [01:20<00:00, 26.91it/s, Loss=nan]\n",
      "Training:  25%|██▌       | 5/20 [2:50:45<8:21:10, 2004.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: nan\n",
      "Epoch 5, Win rate: 0.00, Draw rate: 0.00, Loss rate: 0.00\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1652.85 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2157/2157 [01:19<00:00, 27.19it/s, Loss=nan]\n",
      "Training:  30%|███       | 6/20 [3:19:37<7:26:08, 1912.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: nan\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1867.11 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2086/2086 [01:16<00:00, 27.37it/s, Loss=nan]\n",
      "Training:  35%|███▌      | 7/20 [3:52:00<6:56:29, 1922.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: nan\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 1675.71 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2056/2056 [01:11<00:00, 28.92it/s, Loss=nan]\n",
      "Training:  40%|████      | 8/20 [4:21:07<6:13:16, 1866.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: nan\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n",
      "La carga de datos tardó 2163.84 s\n",
      "Entrenamienot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2086/2086 [01:17<00:00, 26.90it/s, Loss=nan]\n",
      "Training:  45%|████▌     | 9/20 [4:58:29<6:03:40, 1983.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: nan\n",
      "Cargando la muestra de 1000 juegos\n",
      "Procesando los juegos...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "evaluation_interval = 5\n",
    "num_mcts_simulations = 50\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_games = 1000\n",
    "\n",
    "# Optmizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "min_epoch = 0\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "# Envolver el rango de épocas con tqdm para mostrar una barra de progreso\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    st = time.time()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # Aqui debe ir la seleccion aleatoria de N juegos de la lista de juegos games\n",
    "    print('Cargando la muestra de {} juegos'.format(num_games))\n",
    "    sample_games = random.sample(games, num_games)\n",
    "    \n",
    "    print('Procesando los juegos...')\n",
    "    states, policy_targets, value_targets = play_games(model, sample_games, num_mcts_simulations=8, temperature=1.0)\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(np.array(states), dtype=torch.float32),\n",
    "        torch.tensor(np.array(policy_targets), dtype=torch.float32),\n",
    "        torch.tensor(np.array(value_targets), dtype=torch.float32)\n",
    "    )\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print(f'La carga de datos tardó {time.time()-st:.2f} s')\n",
    "    \n",
    "    print('Entrenamienot...')\n",
    "    model.train()\n",
    "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "    for state_batch, policy_target_batch, value_target_batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(model, state_batch, policy_target_batch, value_target_batch, device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({\"Loss\": loss.item()})\n",
    "        epoch_losses.append(loss.item())\n",
    "        \n",
    "\n",
    "    epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    loss_history.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
    "    \n",
    "    min_loss = min(loss_history)\n",
    "\n",
    "    if (epoch + 1) % evaluation_interval == 0:\n",
    "        win_rate, draw_rate, loss_rate = evaluate(model)\n",
    "        print(f\"Epoch {epoch + 1}, Win rate: {win_rate:.2f}, Draw rate: {draw_rate:.2f}, Loss rate: {loss_rate:.2f}\")\n",
    "\n",
    "        if win_rate + draw_rate > min_loss:\n",
    "            min_loss = win_rate + draw_rate\n",
    "            min_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), f\"saved_models/model_epoch_{epoch + 1}_win_rate_{win_rate:.2f}_draw_rate_{draw_rate:.2f}.pt\")\n",
    "            print(f\"Model saved at epoch {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Best model found at epoch {min_epoch}\")\n",
    "\n",
    "# Graficar la pérdida en función de las épocas\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), loss_history, label=\"Loss\")\n",
    "plt.scatter(min_epoch, loss_history[min_epoch - 1], color='red', label=f\"Min Loss at Epoch {min_epoch}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
